---
title: "Who survived the Titanic disaster?  Exploring data with Multinomial Logistic Regression"
author: 'Prepared by: Divij Pherwani (430990) Andrea Furmanek (345183)'
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

# Abstract

Below paper was prepared for the needs of the final project for Advanced Econometrics at the University of Warsaw. By using ``Multinomial Logit Model`` on the data of Titanic survivors we wanted to verify whether the socio-economic status or paying higher fare impacted passenger's probability of survival. The data is originally available on the ``Kaggle`` competition website "Titanic: Machine Learning from Disaster" and contains  data for 1.309 passengers indicating whether they survive, what was their material status, what gender they were, what age they were etc. As our explanatory variables are individual specific (they do not change across alternatives) we decided to use ``Multinomial Logit Model``. In this paper, dependent variable ``Survival`` was explained with different independent variables that were selected using multinomial logit model and verified by statistical tests. The econometric model was built in ``R`` with the use of ``mlogit, survival, stargazer packages``. The end result is a final model with significant variables that best explains survival rate.

__Keywords:__ Titanic, Survival Rate, Multinomial Logit Model, Kaggle Titanic Dataset, Data pre-processing.

# 1. Introduction

The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there were not enough lifeboats for everyone onboard,resulting in the death of 1502 out of 2224 passengers and crew. While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. Therefore this topic seems interesting for further investigation to see which variables influenced survival rate the most.

We will verify the following hypothesis using ``multinomial logit model``:


__Hypothesis 1:__


H0: Having a seat in higher class significantly increases the chance of passenger to survive.  

H1: Having a seat in higher class did not increases the chance of passenger to survive.

__Hypothesis 2:__

H0: Paying a higher fare/having a family member on board increases the chance of passenger to survive.
  
H1: Paying a higher fare/having a family member on board does not increase the chance of passenger survival.


# 2. Literature review

The Titanic disaster resulting in the sinking of the British passenger ship with the loss of 722 passengers and crew occurred in the North Atlantic on April 15, 1912. Although it has been many years since this maritime disaster took place, research on understanding what impacts individual’s survival or death has been attracting researchers' attention. It appears that this is somewhat of a common problem to work on especially that data set is publicly available. Many researchers were exploring this data with different predictive models. For example scientists from Kansas State University applied CART methodology as well as bagging and random forests that provide quite good prediction accuracy at the level of 77%^[Whitley M., “Using statistical learning to predict survival of passengers on the RMS Titanic” K-State Research Exchange, (1), 2015, pp. 32]. Using Logistic Regression also provides satisfactory results, accuracy i.e. almost of about 95%^[Kshirsagar V., Phalke N., “Titanic Survival Analysis using Logistic Regression” International Research Journal of Engineering and Technology (IRJET), (2), 2019, pp. 90] which was obtained by researchers from University of San Francisco. They concluded that the model predicted better with binary dependent variables which means the variable has a binary value as its output. Applying other methods, like random forest model predicts even better than previous models giving 93% of accuracy^[Donges N., “Predicting the Survival of Titanic Passengers” towardsdatascience.com, (3), 2018].


# 3.Dataset and preprocessing

## 3.1.Dataset

The Titanic passenger data consists of a ``training set``, a ``test set`` and a ``gender_submission set`` all are ``.csv`` files. The training set includes the response variable ``Survived`` and 11 other descriptive variables pertaining to 891 passengers. The test set does not include the response variable, but does contain the 11 other variables for 418 passengers. Additionally, gender submission includes only response variables for test set, that's why we started our data preprocessing by merging them. 


From a sample of the RMS Titanic data, we can see the various features present for each passenger on the ship: <br />
__"Survived"__: Outcome of survival (0 = No; 1 = Yes)  <br />
__"Pclass"__: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)  <br />
__"Name"__: Name of passenger  <br />
__"Sex"__: Sex of the passenger  <br />
__"Age"__: Age of the passenger (Some entries contain NaN)  <br />
__"SibSp"__: Number of siblings and spouses of the passenger aboard  <br />
__"Parch"__: Number of parents and children of the passenger aboard  <br />
__"Ticket"__: Ticket number of the passenger  <br />
__"Fare"__: Fare paid by the passenger  <br />
__"Cabin"__: Cabin number of the passenger (Some entries contain NaN)  <br />
__"Embarked"__: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)  <br />


```{r}
library(vcd)
mosaic(~Class+Sex+Age+Survived, data=Titanic, shade=TRUE, legend=TRUE)
```

## 3.2.Preprocessing


```{r message=FALSE, warning=FALSE}
library("sandwich")
library("zoo")
library("lmtest")
library("MASS")
library("aod")
library("nnet")
library("Formula")
library("miscTools")
library("maxLik")
library("mlogit")
library("car")
library("survival")
library("AER")
library("stargazer")
```

As previously mentioned we started our data preprocessing with merging respectively datasets to get complete data for further transformations.

```{r}
dfx <- read.csv("train.csv")
df1 <- read.csv("test.csv")
df2 <- read.csv("gender_submission.csv")
dfy <- merge(df1, df2)
df <- rbind(dfx, dfy)
```


```{r}
head(df)
```

Since the data can have missing fields, incomplete fields, or fields containing hidden or useless information, a crucial step is to remove them in order not to complicate the further analysis. Variables ``Fare`` and ``Embarked`` will not be used, so we decided to remove them. Especially  embarked variable will not be used as is not individual specific. 

```{r}
df <- subset(df, df$Embarked != "")
df <- subset(df, df$Fare != "")
df$Survived <- ifelse(df$Survived == 0, "No", "Yes")
df$Pclass <- as.factor(df$Pclass)
df$Embarked <- as.factor(df$Embarked)
df$Survived <- as.factor(df$Survived)
df$Sex <- as.factor(df$Sex)
head(df)
```

```{r}
summary(df)
```

Our second hypothesis has to verify whether having a family on board has increased the chance of passenger to survive, therefore a new variable ``Family`` has been created as a sum of already existing variables ``SibSp`` - number of siblings and spouses of the passenger aboard and ``Parch``- number of parents and children of the passenger aboard.

```{r}
df$Family <- df$SibSp + df$Parch
head(df)
```

# 4. Application of Econometric Models

```{r}
fdf <- df
fdf <- fdf[,c("Sex", "Pclass", "SibSp", "Parch", "Family", "Embarked", "Survived", "Fare")]
fdf$Farepp <- fdf$Fare/(fdf$Family + 1)
```

```{r}
model1 <- multinom(Survived ~ ., data = fdf)
model2 <- multinom(Survived ~ .-Fare - Farepp, data = fdf)
model3 <- multinom(Survived ~ .-Fare - Farepp-Embarked, fdf)
model4 <- multinom(Survived ~ .-Fare - Farepp-Embarked-SibSp-Parch, fdf)
```


```{r}
summary(model1)
summary(model2)
summary(model3)
summary(model4)
```

log(P(Survived=Yes)/P(Survived=No)) = 3.07093350 + (-3.73011354 * Sexmale) + (-0.75640797 * Pclass2) + (-1.64138819 * Pclass3) + (-0.13429952 * SibSp) + (0.04530608 * Parch) + (-0.08899344 * Family)
+ (-0.03205837 * EmbarkedQ) + (-0.31817849 *EmbarkedS)


```{r}
# statistical significance
z1 <- summary(model1)$coefficients/summary(model1)$standard.errors
z2 <- summary(model2)$coefficients/summary(model2)$standard.errors
z3 <- summary(model3)$coefficients/summary(model3)$standard.errors
z4 <- summary(model4)$coefficients/summary(model4)$standard.errors
```



```{r}
# 2-tailed z test
p1 <- (1 - pnorm(abs(z1), 0, 1)) * 2
p2 <- (1 - pnorm(abs(z2), 0, 1)) * 2
p3 <- (1 - pnorm(abs(z3), 0, 1)) * 2
p4 <- (1 - pnorm(abs(z4), 0, 1)) * 2
```

```{r}
stargazer(z1,z2,z3,z4, type = "text")
```

```{r}
stargazer(p1,p2,p3,p4, type = "text")
```

```{r}
stargazer(model1, model2, model3, model4, type = "text")
```



```{r}
fdf <- df[,c("Survived", "PassengerId", "Pclass", "Sex", "SibSp", "Parch", "Embarked", "Family", "Fare")]
fdf$Farepp <- df$Fare/(df$Family+1)
mldf <- mlogit.data(fdf, shape = "wide", choice= "Survived", v.names=c("PassengerId"))
```

```{r}
model <- mlogit(Survived~ 0| Sex + Family + Pclass, data = mldf)
model
```

```{r}
summary(model)
```
```{r}

#model <- mlogit(Survived~ Fare+Farepp | Sex + Family + Pclass, data = mldf)
#model

```





```{r}
# a) general-to-specific method for variables selection




```



```{r}
# b) at least one nonlinear relationship (variable to a power) and interaction between variables

fdf$Fare2 <- fdf$Fare^2
fdf$Farepp2 <- fdf$Farepp^2
nlr_model1 <- multinom(Survived ~ Fare + Farepp + Fare2 + Farepp2, data = fdf)
nlr_model2 <- multinom(Pclass ~ Fare + Farepp + Fare2 + Farepp2, data = fdf)

summary(nlr_model1)
summary(nlr_model2)


# ? Interactions 

```


```{r}
# c) calculation and interpretation of marginal effects for the final model (from the general-tospecific approach)



model<-mlogit(Survived~0|Fare+Family+Sex, data=mldf)
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}

mldf$Sex

#mldf$Sex[mldf$Sex=="male"] <- 1
#mldf$scode[mldf$Sex=="female"] <- 0

mldf$Sex

z <- with(mldf, data.frame(Sex=tapply(Sex, index(model)$alt, mean),
                            disp=tapply(Fare, index(model)$alt, mean),
                            price=tapply(Family, index(model)$alt, mean)))
z[,1:2] = 1
z



```



```{r}
#present the general model, the final model (the specific model) in one quality table. If there is space, at least one intermediate model might be presented


# Easy in the end using stargazer

```


```{r}
linktest = function(model) {
  # written by dr Rafal Wozniak, Faculty of Economic Sciences, University of Warsaw
  # 2019-04-18
  #
  # arguments:
  # ------------------
  # model - model estimated by glm function
  
  # check if it is of class 'glm'
  
  # Linktest
  y = model$y
  yhat = log(model$fitted.values/(1-model$fitted.values))
  yhat2 = yhat^2
  # auxiliary regression
  aux.reg = glm(y~yhat+yhat2, family=binomial(link=model$family$link))
  show(summary(aux.reg))
  return(aux.reg)
}
```


```{r}
# e) perform the linktest and interpret the result
mylogit <- glm(Survived~ Sex + Pclass, data=fdf, family=binomial(link="logit"))
linktest(mylogit)
```

# References



